Automating the Practice of Science - Opportunities, Challenges, and Implications
Sebastian Musslick*a, Laura K. Bartlettb, Suyog H. Chandramoulic, Marina Dubovad, Fernand Gobetb,e, Thomas L. Griffithsf, Jessica Hullmang, Ross D. Kingh, J. Nathan Kutzi, Christopher G. Lucasj, Suhas Maheshk, Franco Pestillil, Sabina J. Slomanm, and William R. Holmesd
This manuscript was compiled on September 11, 2024


Automation transformed various aspects of our human civilization, revolutionizing industries and streamlining processes. In the domain of scientific inquiry, automated approaches emerged as powerful tools, holding promise for accelerating discovery, enhancing repro- ducibility, and overcoming the traditional impediments to scientific progress. This article evaluates the scope of automation within scientific practice and assesses recent approaches. Furthermore, it discusses different perspectives to the following questions: Where do the greatest opportunities lie for automation in scientific practice?; What are the current bottlenecks of automating scientific practice?; and What are significant ethical and practical consequences of automating scientific practice? By discussing the motivations behind automated science, analyzing the hurdles encountered, and examin- ing its implications, this article invites researchers, policymakers, and stakeholders to navigate the rapidly evolving frontier of automated scientific practice.

Automation | Computational Scientific Discovery | Metascience |
AI for Science

"Though the world does not change with a change of paradigm, the scientist afterward works in a different world."
- Thomas S. Kuhn, The Structure of Scientific Revolutions

Automation is transforming every domain of scientific inquiry, from the study of functional genomics in biology (1, 2) to the derivation of conjectures in mathematics (3, 4). Recent advances in automation are accelerating hypothesis generation in chemistry (5-8), material discovery in materials science (9, 10), and theory development in psychology (11). These breakthroughs are not only garnering attention but also an uptick in funding and prizes dedicated to the automation of scientific practice (12-14). Furthermore, concurrent advancements in artificial intelligence, software, and computing hardware are setting the stage for even more extensive automation within the scientific process (15-17).
   The impact of automation in industry serves as a parallel to its potential in science. In the early 20th century, industrial automation began with mechanized assembly lines, revolutionizing manufacturing efficiency and output. The introduction of robotics and computer-aided manufacturing marked another leap, enabling precision and consistency previously unattainable by human labor. Today, industry-wide automation facilitates not just cost-efficient mass production, but also customized, adaptable, and intelligent manufacturing processes. This evolution demonstrates the capac- ity of automation to radically redefine operational paradigms.
   Drawing parallels to scientific practice, one can anticipate a similar trajectory of profound change, where automation could ac- celerate discovery, reshape research methodologies, and redefine the very nature of scientific inquiry. At the same time, automation in industry had significant impacts on workers and the kind of products that dominate the marketplace. It is thus important to

consider parallel impacts in the scientific setting which may have negative consequences for science and society.
   In this perspective, we evaluate what automation should and can achieve for scientific practice. In doing so, we outline the current state of science automation, drawing on recent examples from different domains of science. Furthermore, we examine technological advancements that open new avenues for automation in science, and discuss current bottlenecks. Finally, we highlight a selection of practical and ethical considerations, and discuss how automation may lead scientists to work in a different world, one where traditional methodologies are redefined and new meta- paradigms for science emerge.

What are the bounds of automating scientific practice?
Scientific practice can be defined as the set of methods and processes used by scientists to acquire knowledge about the natural world. Automation, in its broadest sense, refers to the use of technology to perform tasks with minimal human intervention. In the context of scientific practice, automation specifically denotes the use of technological tools and systems to carry out scientific tasks or processes traditionally performed by human scientists.
   The bounds of automation within scientific practice hinge on at least two questions: First, is there a desire and justification for automating a given scientific practice? This question touches upon goal-related bounds-the alignment of automation with the overarching goals of science. Second, what factors characterizing

Author affiliations: aInstitute of Cognitive Science, Osnabru¨ ck University, 49090 Osnabru¨ ck, Germany; Department of Cognitive, Linguistic, & Psychological Sciences, Brown University, Providence, RI 02912, USA, ORCID; bCentre for Philosophy of Natural and Social Science, London School of Economics, Lakatos Building, Houghton Street, London, WC2A 2AE, UK, ORCID; cDepartment of Information and Communications Engineering, Aalto University, P.O. Box 11000 (Otakaari 1B) FI-00076 AALTO, Finland; Department of Computing Science, University of Alberta, 8900 114 St NW, Edmonton, AB T6G 2S4, Canada ORCID; dCognitive Science Program, Indiana University, 1101 E 10th St, Bloomington, IN 47405, USA, ORCID; eSchool of Psychology, University of Roehampton, London, SW15 4JD, UK ORCID; fDepartments of Psychology and Computer Science, Princeton University, Princeton, NJ, USA, ORCID; gDepartment of Computer Science, Northwestern University, IL, USA, ORCID; hDepartment of Chemical Engineering and Biotechnology, University of Cambridge, Cambridge, CB3 0AS, UK; Department of Computer Science and Engineering, Chalmers University of Technology, Gothenburg, 412 96, Sweden; ORCID; iDepartment of Applied Mathematics and Electrical and Computer Engineering, University of Washington, Seattle USA 98195, ORCID; jSchool of Informatics, University of Edinburgh, 10 Crichton St., EH8 9AB, United Kingdom, ORCID; kDepartment of Materials Science and Engineering, University of Toronto, Canada, ORCID; lDepartment of Psychology and Department of Neuroscience, The University of Texas, Austin, TX, USA, ORCID; mDepartment of Computer Science, University of Manchester, M13 9PL, UK ORCID


Author contributions. Based on the perspectives submitted by all authors, SM and WRM outlined the initial draft, and SM wrote the initial draft. All authors revised the initial draft and contributed to revisions that were incorporated into the final version.
*To whom correspondence should be addressed. Sebastian Musslick, In- stitute of Cognitive Science, Wachsbleiche 27, 49090 Osnabru¨ ck, Germany, sebastian.musslick@uos.de

a scientific practice influence the feasibility of automating that practice? This aspect focuses on the technological bounds, assessing the practicality and potential constraints of applying automation in science.


Goal-related bounds: what automation should (not) achieve. Science is driven by normative and epistemic goals. Here, we discuss arguments for and against automation serving these goals. The normative goals of science involve ethical, moral, and societal values guiding both basic and applied science. One such goal may be to enable cheap and fast discoveries that advance human health. Along these lines, automation can serve to yield faster scientific discoveries with fewer resources. This is particularly desirable in the applied sciences, e.g., for identifying novel drugs or treatments. Thus, automation can aid scientific practice if societal needs are clear and research questions are well defined. However, the process of identifying a research question itself requires considering societal needs or the interests of the scientific community. As noted in the Opportunities section below, generative artificial intelligence (AI) can integrate large bodies of literature to identify societally and scientifcally important gaps in our knowledge that are worth filling. However, since the relevant normative considerations inherently depend on evolving human contexts, it can be argued that humans ought to always be involved in and monitor the degree to which scientific practices achieve these objectives (18). Consequently, full automation in these areas might not only be impractical but also undesirable, underscoring the indispensable role of human scientists in addressing the normative
dimensions of science.
   The epistemic goal of science is to understand the natural world through description, prediction, explanation, and control. As discussed in the sections that follow, advances in machine learning can aid in automating the description or explanation of natural phenomena. Such automation can help reduce human errors and biases, leading to more accurate predictions and better control of natural phenomena. Even more so, automation may help bypass or augment the cognitive capacities of human researchers (19), enabling degrees of prediction and control unachievable for human cognition alone. For example, machine learning models can generate millions of proposals for novel materials that lie beyond human intuition (9). Yet, the increase in precision achieved through automation presents an epistemic dilemma, as automation can limit human understanding. In the basic sciences, advancement of human understanding may be more desirable than merely improving predictability through automation. The complexity of a machine learning model, for example, might enhance its ability to accurately predict new stable materials, but concurrently obscure the process by which these predictions are made for human scientists. This scenario illustrates a potential conflict between the scientific objectives of enhancing prediction, on the one hand, and enabling human understanding, on the other (see Practical Implications). This suggests keeping human scientists involved in the scientific process rather than minimizing their involvement. Meanwhile, in applied sciences and engineering, the focus might shift towards maximizing prediction and control, providing a stronger case for automation of scientific practice.

Technological bounds: what automation can (not) achieve. The technological bounds of automation hinge on the difficulty of automating scientific tasks. Here, we discuss four factors characterizing this difficulty (Figure 1). These factors indicate both




Fig. 1. Factors determining the technological reach of automation in scientific practice.


opportunities and barriers to automation, thereby guiding the iden- tification of areas within scientific practice where automation can be most effectively implemented or where it may face challenges. The first factor concerns the availability and quality of inputs that a scientific task requires. Some tasks, such as identifying a research question, rely on diverse and sometimes subjective inputs, including peer opinions, news articles, or funding announcements.
Such inputs may not be trustworthy, widely accessible or structured for machine processing, posing a challenge to automation.
   Another limiting factor for automation is the computational complexity of algorithms available to perform a scientific task. For example, identifying an appropriate experiment for testing a research question may require taking into account numerous decision variables (e.g., internal validity, resources needed, novelty) and searching an exponentially increasing space of possible experimental paradigms, which can be computationally intractable. A related, yet often overlooked, factor influencing the automa- tion of scientific tasks is the complexity of required hardware engineering. As stated in Moravec's paradox, sensorimotor tasks, like executing invasive brain recordings or social experiments, re- quire advanced solutions in robotics to facilitate automation, which can pose more significant challenges to automation compared to
cognitive tasks (20).
   Finally, some tasks are difficult to automate because of the subjectivity of the task goal. Some scientific goals cannot be easily turned into a well-defined objective, which is required to communicate it to a machine. For instance, choosing between scientific models can be a matter of personal preference (21).
   While the four factors collectively dictate the automatability of scientific tasks, they can be considered interdependent. For example, the automated discovery of scientific equations long relied on search methods with high computational complexity, such as evolutionary computation or brute force search, to identify a set of equations that best describes a given data set (22, 23). However, the ability to collect large datasets cheaply, paired with improvements in computing hardware, enables the application of "data-hungry" but computationally tractable machine learning algorithms for equation discovery (24-27). This approach reduces computational complexity, illustrating how enhancements in one factor can compensate for limitations in another.

Automation in current scientific practice
Existing approaches to automating science target tasks with readily available inputs, computational complexity and hardware demands that align well with current technological capabilities, and clear task goals. Accordingly, efforts at automatization in science have mostly been confined to tasks characterized by clearly specified objectives and well-defined subtasks, which include instances of quantitative hypothesis generation, experimental design, data collection, and quantitative analysis and inference. While covering all advances

is out of the scope of this article, we highlight a subset of these approaches, focusing on cases that facilitated novel discoveries.

Hypothesis generation. Hypothesis generation is the develop- ment of testable statements that are based on observations, existing knowledge, or theory. Advances in automated hypothesis generation were primarily driven by two factors: improvements in computer algorithms, and the availability of large datasets.
   Initial automated hypothesis formation approaches relied on symbolic reasoning systems. For example, in organic chemistry, logical deduction based on existing knowledge was employed to formulate hypotheses about the chemical constituents of body fluids (28). Furthermore, quantum simulations, facilitated through cloud computing, became the backbone of hypothesis generation for materials properties (29, 30). The development of efficient search algorithms further expanded the scope of automated hypothesis formation to areas with large hypothesis spaces (3). For instance, hypothesis generation in mathematics leveraged efficient machine learning algorithms to identify novel conjectures about fundamental constants (3). Finally, deep learning enabled more breakthroughs in chemistry. A landmark achievement in this area is AlphaFold, which predicts 3D protein structures from amino acid sequences, facilitating the development of drugs (6).
The availability of large data sets led to further advances
in automated hypothesis formation. One example is the field of biomedicine, where large gene databases led to a surge in hypothesis generation with computational methods, e.g., using data mining and network analysis to propose genes that may be linked to diseases (31, 32). Similarly, existing materials databases provided sufficient information for machine learning methods to generate over 2.2 million proposals for novel materials that, so far, escaped human intuition (9).

Experimental design. The problem of automated experimental design is to systematically identify the most informative experiment to address a particular hypothesis or scientific question. The informativeness of an experiment can be evaluated in various ways. Some automated experimental design methods are geared towards identifying the experimental conditions that minimize the influence of nuisance variables--experimental variables that are not of interest but can pollute the informativeness of intended experimental manipulations (33, 34). Other methods aim to find experimental conditions that are well suited to identify a scientific model of interest (35-37). This problem of experimental design is closely related to the problem of active learning in machine learning research (2, 38-40), which seeks to identify data points that can best inform a machine learning model when included as training data. A prominent active learning method used for scientific practice is Bayesian optimal experimental design, which has been successfully applied in various fields, including psychology (36, 37, 41, 42), neuroscience (43), physics (44, 45), biology (46, 47),
chemistry (48, 49), materials science (50-52), and engineering
(53). For example, in the domain of psychology, Bayesian optimal experimental design led to the discovery of novel models of how humans discount the future relative to the present (54).
   While automated experimental design methods can facilitate efficient data collection and strong inferences, their efficacy can be compromised if the underlying assumptions are violated or if the scientific model is incorrectly specified (55-57). This limitation led to unexpected findings in simulation studies, where random sampling of experimental conditions outperformed automated theory-driven approaches to experimental design (38, 58), and

where uniform sampling outperformed adaptive approaches in learning continuous relationships (59).
   Another limitation of current approaches to automated experi- mental design pertains to their scope, as they focus on navigating a pre-defined space of experimental manipulations. Exploring novel research directions, however, often involves identifying completely new experimental manipulations (60).

Data collection. Data collection, often a time-consuming and costly aspect of empirical research, is a significant bottleneck in scientific discovery. Accordingly, automated tools for data collection emerged as some of the most impactful innovations in accelerating the pace of science. These tools span a wide range of applications and fields: fitness trackers revolutionized public health studies (61), continuous glucose monitors are providing critical insights into nutrition and diabetes research (62), and automated weather stations enhanced meteorological predictions (63). In addition to providing streams of real-time data for ongoing analysis, these automated systems can minimize human observation and experimenter biases. Experimenter bias occurs when the beliefs, expectations, or preferences of the researcher unconsciously influence the conduct or outcome of an experiment. Automating data collection in animal studies helped to eliminate experimenter bias, resulting in refutations of previous results, such as the evidence for statistical learning ability in newborn chicks (64). A particularly noteworthy advancement in the behavioral sciences was the adoption of web-based experiments, especially during the COVID-19 pandemic. Online platforms and interfaces for recruiting and conducting experiments did not only facilitate the collection of behavioral data at a time when traditional lab-based studies were impractical, but they also broadened the scope and diversity of participants (65-67). Automating data collection also generated opportunities for automating other elements of behavioral science, such as adopting adaptive experimental designs that change based on the responses of participants (68) or collecting larger datasets that can support the use of machine-learning algorithms (11).

Statistical inference. The automation of statistical inference transformed dramatically from the era of manual computations, a reality echoed in old statistical textbooks filled with computation- simplifying shortcuts. The introduction of computers altered statistical methodologies, sometimes even leading to their re- placement by machine learning techniques. For example, modern statistical inference engines, like Stan, leverage techniques such as Markov Chain Monte Carlo (MCMC) for efficient sampling of model parameters (69). Tools for likelihood-free inference enable the analysis of statistical models that are not mathematically tractable. Furthermore, frameworks such as Bayesian Workflow (70) and platforms such as the Automatic Statistician (71) are streamlining complex processes like Bayesian inference and the construction of traditional statistical models. The automation of statistical inference, however, is mostly confined to the deduction of new knowledge based on pre-specified statistical models.

Scientific inference and model discovery. Scientific inference, unlike statistical inference, involves generating hypotheses about observations (abduction) and generalizing from observations to laws or broader theories (induction). The automation of scientific inference is termed computational scientific discovery and has so far centered on identifying models or laws that elucidate specific phenomena (22, 23, 72). One instance of computational scientific

discovery involves the identification of equations ("symbolic re- gression") to uncover quantitative laws governing a given data set. Early efforts relied on heuristic search techniques to rediscover insights from mathematics (73, 74) or physics (75). Advances in machine learning and high-performance computing facilitated equation discovery, building on reinforcement learning (26), genetic algorithms (25, 76, 77), MCMC sampling (78), mixed-integer nonlinear programming (79), or gradient-based search techniques (24, 27, 80, 81). However, most forms of computational model
discovery are limited to the rediscovery of existing knowledge.	B Possible exceptions include the discovery of scaling laws and boundary equations in plasma physics (82) and novel models of
human decision-making (11).

Closed-loop automation spanning multiple scientific prac- tices. Demonstrations of successful closed-loop automation in empirical research-implementing iterations between experimental
design, data collection and model discovery-mark a significant    C
progression for automated scientific practice. One pioneering example is the robot scientist Adam (Figure 2A), which was the first fully automated machine to discover novel scientific knowledge
(2). Adam investigated the functional genomics of the yeast S. cerevisiae, and discovered the function of locally orphan enzymes- enzymes known to be in yeast but for which the gene(s) encoding them were unknown. The successor of Adam, Eve, is a robot


Functional Genomics (Adam)



Material Science (A-Lab)


Behavioral Science (AutoRA)



scientist designed for early-stage drug development (39), which identified chemical compounds that outperformed standard drug screening. Eve's most significant discovery is that triclosan (an antimicrobial compound commonly used in toothpastes) may aid against malaria (39, 83, 84). Another example of a closed-loop discovery system in biology is Wormbot-AI, a platform designed to autonomously conduct experiments on the longevity of worms, capable of testing thousands of interventions annually (85, 86).
   Complete automation also gained momentum in materials science and chemistry, where efforts are focused on integrating hypothesis generation, decentralized experimentation, and cloud- based decision-making. For instance, modular robotic platforms, driven by machine learning algorithms, were used to optimize material properties by varying synthesis conditions (87-89). One notable example is A-Lab (Figure 2B), an autonomous laboratory for the solid-state synthesis of inorganic powders, which leverages a combination of active learning and machine learning models trained on the literature, to propose novel material candidates (10).
   Additionally, behavioral research became amenable to closed- loop automation with the ability to collect data via online experi- ments. Open-source tools like AutoRA (90) facilitate closed-loop research by integrating automated model discovery, experimental design, and experimentation in empirical research. AutoRA effectively interfaces with web-based platforms for automated data collection, integrating the acquisition of behavioral data from human participants. While the potential to yield novel discoveries stands to test, AutoRA served as a computational testbed for philosophy of science, exposing cases where random experimentation outperforms model-guided experimentation (38).
   Finally, researchers introduced an LLM-based agent for au- tomating empirical machine learning research, from idea devel- opment and experimental design to execution and data analysis, e.g., for improving existing machine learning models (91). Notably, this system also leveraged LLMs to automate the writing and peer review of the resulting research manuscript, with the computational cost of one article estimated to be just 15 USD.

Fig. 2. Closed-loop automation systems. (A) Adam for functional genomics. (B) A-Lab for materials science. (C) AutoRA for behavioral science. Dashed boxes list knowledge and processes provided by human researchers.


   Despite their potential to accelerate scientific discovery, it is important to recognize that the pioneering examples of closed-loop automation are currently confined to specific, automatable research steps and operate within a constrained range of experimental design and model spaces as delineated by human researchers.

Future opportunities
Existing approaches for automating scientific practice primarily target tasks for which (a) high-quality data is available, (b) the computational complexity can be addressed by current algorithms, and (c) hardware complexity is manageable. The most promising prospects for future automation in scientific practice are found in tasks traditionally limited by human cognitive capacities. This includes areas requiring the processing of large volumes of high- dimensional data or exhaustive literature searches. In this section, we highlight a few technological trends that promise to push the boundaries of science automation along these lines.

Data collection, standardization, and sharing. Advancements in cost-effective data collection, standardization, and sharing signifi- cantly boost the automatability of scientific practices, particularly those dependent on empirical data. For example, in the behavioral sciences, the utilization of crowd-sourced experimentation plat- forms like Amazon Mechanical Turk and Prolific revolutionized the efficiency of behavioral data collection. Additionally, LLMs that can mimic human behavior were proposed as proxies for participants, aiding in the acquisition of large-scale datasets (92). Once ac- quired, such large-yet cost-efficient-datasets can empower data- hungry machine learning algorithms, enabling them to uncover novel, and more precise models of human behavior (93-96). Large- scale data collection, however, still bears significant hardware

challenges, e.g., for collecting biological samples from a large number of participants (see Future challenges). Nevertheless, the data quality needed for automated analysis techniques should be complemented by data standardization and sharing.
   Scientific data sharing platforms, such as the Open Science Framework, facilitated the availability and accessibility of data needed for automated analyses and computational discovery. The potential of data sharing and standardization is perhaps best illustrated in materials science, where databases for stable materials enabled the prediction of large quantities of new materials
(9). Other scientific domains profit from similar efforts. For example, in neuroscience, archives like DANDI, OpenNeuro, DABI and BossDB allow researchers to share data using community standards (97), such as BIDS for neural data (98).

Combining data-driven and knowledge-driven discovery. A particularly promising approach to automating scientific discovery is the integration of pre-existing human knowledge into the discovery process. Traditionally, data-driven discovery methods operated with minimal prior knowledge about the specific domain of scientific inquiry. This pure data-driven approach makes such methods particularly susceptible to noisy data. However, recent work demonstrates that incorporating prior theoretical knowledge can significantly aid in recovering scientific models from noisy datasets. For example, Bayesian symbolic regression exhibits greater efficacy in recovering equations from noisy data when given priors about scientific equations extracted from Wikipedia (78, 99). Similarly, embedding prior knowledge in the form of general logical axioms proved instrumental in rediscovering complex scientific laws, including Kepler's third law of planetary motion and Einstein's relativistic time-dilation law (79, 100). Furthermore, experiments with the BacterAI, which uses active learning for the automated study of microbial metabolisms, have demonstrated the advantage of leveraging relevant prior knowledge (101). Specifically, when the metabolic model trained on one bacterial species was retrained for the species of interest, it more efficiently discovered its metabolic model compared to starting the learning process from scratch, despite the two species differing in their metabolic capabilities. These examples highlight the benefits of combining data-driven and knowledge-driven approaches for automated model discovery.
   The benefits of knowledge-driven discovery are, however, fundamentally limited by the quality of prior knowledge. For example, Bayesian adaptive experimentation can be misled if prior knowledge mischaracterizes the data (102, 103). Thus, data-driven approaches to computational model discovery become particularly beneficial when dominant scientific models in the em- pirical sciences are more informed by (wrong) theory versus data. This is evident in computational models of human reinforcement learning, which predominantly rely on classic machine learning algorithms (104). Recent work demonstrated that a data-driven model discovery can uncover novel reinforcement learning models that better explain human learning than traditional models (95).
   Finally, a notable area of progress in automated model dis- covery is the analysis of high-dimensional datasets, such as fluid dynamics captured in video format, through reduced-order modeling. This process involves learning a low-dimensional representation of the dynamics inherent in complex data and then decoding the governing equations of these latent dynamics (105-108). Similar approaches were developed to automate the discovery of neural data embeddings correlating with behavioral dynamics (109). These approaches promise to extend the reach

of automated model discovery to high-dimensional naturalistic datasets. beyond experimental control.

Generative AI and LLMs. Generative AI and LLMs offer paths towards automating scientific practices that have historically been challenging due to their computational complexity and qualitative nature (8, 16, 91, 110). Among these are the synthesis and integration of literature, and documentation of findings.
   Researchers argued that LLMs show promise in enhancing literature reviews, a task currently limited by the cognitive con- straints and language barriers of human scientists (111, 112). Whereas humans may only be able to parse and integrate a few hundred articles into a literature review-the scope of which is heavily influenced by the expertise and biases of the researcher-LLMs may accomplish literature synthesis in the order of thousands or millions of articles. Critically, LLMs can take into account articles written in different languages, thus helping to counter the dominance of Western perspectives in scientific literature. Thus, LLMs can assist in extending or even bypassing human researchers' cognitive limitations. A notable application of LLMs for the purpose of literature synthesis is Elicit, which utilizes LLMs trained on paper abstracts to support and help researchers extract relevant information from the scientific literature
(112). Another instance of such assistance is an LLM-based "co-
scientist" for chemical research, which improved the planning of chemical syntheses based on extensive information available on the internet, and aided in the navigation of extensive hardware documentation (8). Additionally, BrainGPT-an LLM fine-tuned to the neuroscience literature- demonstrated the capability to outperform human experts in predicting the results of neuroscience experiments (113).
   Combined with their capability for literature synthesis, LLMs can foster the discovery of new research directions and hypotheses
(91). Along these lines, LLMs have the potential to expand experimental design spaces, addressing a common bottleneck in automated scientific practice. While traditional automated experimentation is confined to researcher-defined variables (cf. Figure 2), LLMs could identify novel experimental variables of interest, thus broadening the scope of scientific inquiry. However, it can be argued that LLMs risk rediscovering already known hypotheses and experiments (18).
   Once experiments are designed, LLMs may aid in the balanced documentation and communication of the research study, including the automated documentation of research code (114, 115). Apart from aiding in the construction of research articles, LLMs can enable automated translation into multiple languages. This ad- vancement is particularly beneficial for non-native English speakers and is an example of how automation and AI can address ethical challenges in science. Nevertheless, literature reviews conducted by human scientists serve not only to synthesize knowledge but also to build and refine the conceptual frameworks of evolving scientists-a process that is critical to scientific training and that is challenged by the overuse of LLMs for literature synthesis.

Future challenges
Despite recent advances and opportunities for the automation of science, there remain substantial obstacles. This section examines technological bounds rooted in four bottlenecks (cf. Figure 1): limited availability and quality of data, intractable computational complexity of certain scientific tasks, lack of required hardware, and subjectivity in assessing the outputs of scientific tasks. These

bottlenecks highlight why barriers to automation remain difficult to surmount in the basic sciences (as opposed to engineering), at least with the technologies and methodologies currently at our disposal. Addressing these challenges will require significant interdisciplinary efforts to identify solutions that enable automation beyond a few selected domains of scientific inquiry.

Limited availability and quality of inputs. Prior applications of computational discovery, such as in chemistry (5, 7, 116) and materials science (9, 10), relied on standardized formats for both data and scientific hypotheses that are easily parsed by machine learning algorithms. However, most tasks of scientific practice rely on a diversity of representations for scientific knowledge. For example, computational models in the natural sciences are expressed in various formats, such as equations embedded in scientific articles or computer code written in different programming languages. Without standardization across disciplines, automated systems face significant challenges in drawing parallels or applying concepts from one domain to another. Efforts to standardize the representation of scientific models and other forms of scientific knowledge promise to ease the automation of scientific practices relying on such knowledge (117). However, even if data is standardized and widely available, ensuring its quality remains critical. For instance, literature synthesis enabled by LLMs may be unfruitful or even misleading if fraudulent or unreproducible papers are included as inputs to these models. Therefore, robust quality control measures must accompany standardization efforts to maintain the integrity and usefulness of automated systems.

Computational complexity. One of the fundamental bottlenecks in the automation of scientific practice lies in the computational complexity of many scientific tasks. For example, complexity analyses within the realm of cognitive science indicate that scientific discovery in cognitive science may be computationally intractable in principle, even with unlimited availability of data
(118). These theoretical results suggest that uncovering a definitive "ground-truth" theory may be beyond the reach of computation.
   One potential critique of leveraging computational methods for scientific discovery hinges on the incomplete comprehension of the cognitive processes, and the concomitant computational complexity underlying it. One may argue that without a full grasp of how humans tackle scientific inquiries, designing algorithms capable of similar feats seems implausible. However, at least two counterarguments challenge this perspective. First, replicating natural processes is not a prerequisite for solving problems. For instance, modern airplanes achieve superior lift not by emulating the flapping motion of birds but through aerodynamically efficient designs. Second, a deep understanding of cognitive phenomena is not a strict requirement for automation, as evidenced by the capa- bilities of LLMs to produce coherent natural language sequences without humans having a complete scientific understanding of language generation. Nonetheless, this gap in understanding underscores the importance of implementing robust evaluation methods to ensure the accuracy and mitigate any potential negative impacts of automating scientific processes.

Hardware engineering. The advancement of automated science is significantly hindered by current limitations in laboratory robotics and hardware engineering. For instance, executing complex biolog- ical or physics experiments remains challenging. Moreover, while robotic automation has been successfully implemented in certain areas, such as with the robot scientist concept (1, 2, 101, 119),

its application is primarily limited to clearly defined engineering problems. Yet, even well-defined engineering problems must manage the noise and variability inherent in the data collected by sensors, which can dramatically affect the reliability of scientific outcomes. Therefore, while progress has been made in automating scientific practice, developing more sophisticated robotics to handle complex, noisy data is crucial for its broader adoption and effectiveness.
   The automation of hardware tasks in scientific practice is also hindered by the need for highly specialized equipment, leading to significant capital expenditures, often exceeding millions of dollars. Such custom-built hardware is typically field-specific and lacks versatility for reuse in other scientific domains. This challenge is evident in the limited cross-utilization of hardware between disciplines, as seen in the relatively small amount of equipment that materials scientists have been able to adapt from the more heavily automated field of drug discovery. Addressing this issue requires a strategic approach where, for each scientific field, scientists identify and develop a core set of automated hardware that can deliver the greatest impact. This not only involves designing equipment that meets the unique needs of each field but also balancing specificity with adaptability, to maximize utility and cost-effectiveness.

Subjective goals of scientific tasks. More than in engineering, practices in basic science are inherently subjective in how the outcomes of those practices are evaluated. This challenge is particularly evident in developing AI capable of generating novel and impactful scientific ideas. Novelty and impact involve a high degree of subjectivity and variability, making it difficult for these systems to replicate human judgment in the space of scientific inquiry (16). This issue is compounded by the personal aspect of scientific practice. The selection of scientific projects is guided by the personal experience and perspective of human scientists. Di- versity in such perspectives paired with interdisciplinary exchange can lead to a greater diversity of ideas in human scientific systems (120)-a dimension that AI currently cannot emulate without explicit instruction. Furthermore, the lack of standardized solutions in many scientific areas means that automating these tasks risks constraining exploration, which is vital for scientific advancement. Moreover, interpretation of data patterns and hypothesis gen- eration often necessitates human judgment to translate statistical regularities into meaningful scientific interpretations. Techniques like topic modeling, while effective in identifying text co-occurrence patterns, require human insight to align these patterns with relevant scientific constructs (121). The role of human judgment is perhaps best exemplified in serendipitous discovery, often stemming from unexpected failures or results. For example, Alexander Fleming's discovery of penicillin began with the accidental contamination of a Petri dish. Instead of discarding it, his observation of the bacteria being killed by the mold led to the development of the first antibiotic. These aspects highlight the crucial role of human
judgment in scientific discovery.

Implications
Although the automation of science currently faces significant limitations, the extent to which it will evolve in the mid- to long- term remains an open empirical question. As advancements in hardware and algorithms continue, the range of practices subject to automation is likely to expand. In this section, we explore the practical and ethical consequences of this trend.

Practical implications.

The role of human scientists and the paradox of automation. The advancement of automation in scientific practice raises consider- ations regarding the future role of human scientists. On the one hand, it can be argued that automation reduces the need for human involvement. Scientific discovery systems may become able to monitor themselves and tune themselves to optimal performance- potentially excluding humans from the scientific discovery loop. On the other hand, it can argued that the greater the efficiency of an automated system, the more vital the role of human oversight (122). A critical assumption underlying this "paradox of automation" is that automation is not perfect; the potential for accumulating errors necessitates human intervention. If automation were flawless, human oversight would be unnecessary, and the paradox would not exist. However, for tasks with sufficient complexity and uncertainty, this paradox suggests that, in highly automated environments, human contributions, though less frequent, are more critical. This may specifically apply to tasks that demand subjective assessment or the synthesis of complex data, such as reviewing scientific literature, as well as high-level responsibilities such as strategic allocation of funds for scientific inquiry.
   Even in the absence of subjective assessment, there are inherent risks associated with automation. For instance, an error within an automated system can lead to a cascade of compounded errors, persisting and potentially amplifying until the system is either corrected or deactivated. This may be particularly problematic for automation methods whose decision- making processes are not completely predictable, as is the case for many machine learning algorithms. This unpredictability raises the issue of responsibility for unintended consequences such as injuries. Given the potential severe legal and financial implications of compounding errors in automation, the involvement of human scientists, even in areas where automation is technically feasible, may prove to be more efficient, practical, and safe in the near future. Thus, the paradox of automation underscores the lasting importance of human expertise and the need for a balanced approach that combines automated systems with human judgment.

Research training. With increased automation of science, there arises a need to reevaluate and adapt scientific education. This new landscape calls for training that encompasses not only traditional scientific knowledge but also skills for effectively working alongside automated scientific discovery systems. For instance, obtaining valuable outputs from LLMs is becoming an essential skill. Moreover, scientists will need to develop competencies in understanding and evaluating the functioning and outputs of automated systems, as is already demanded for statistical software
(47). This shift implies a growing demand for engineers, scientists, and technicians proficient in advanced STEM skills.

Research evaluation. The current pace of science is primarily determined by our capacity to carry out the research itself. Laboratory studies in fields like biology and chemistry can take years, contrasting with the relatively quick peer review process. However, if advancements in automation enable research to be conducted and documented several magnitudes faster (91), this could lead to a substantial increase in the rate of research article submissions. Such a scenario would further strain the already pressured peer review system. One potential solution could be the automation of peer review, possibly through the use of LLMs; however, this approach has already faced restrictions and bans in

certain contexts due to concerns about its efficacy, reliability, and confidentiality (123). Another potential solution is for journals to require that articles generated by automated systems be accom- panied by critical evaluations from corresponding human authors. This ensures that human researchers retain comprehension and oversight of what is being submitted while also serving as initial reviewers of the work generated by their automated systems. Either way, this shift would necessitate a reevaluation of the peer review process, ensuring it remains rigorous and effective in the face of increased scientific productivity.

Scientific methods. The automation of scientific practice has the potential to bring about a shift in scientific methods that goes beyond mere acceleration of scientific discovery. As discussed above, the use of machines for scientific discovery allows us to move beyond the cognitive and physical constraints inherent to human scientists (19). Consider, for example, the principle of parsimony in the construction of scientific models. Traditionally, parsimonious models have been favored for their superior general- ization, ease of interpretation and communicability among human scientists. However, as discussed in (21), recent studies suggest that highly complex models can, under certain conditions, surpass the generalization capabilities of simpler ones (124), leading to unprecedented advances in scientific research (e.g., for 3D protein folding (6) or material discovery (9)). Moreover, as explored in (21), the development of such complex models is often a prerequisite for discovering successful parsimonious models (e.g., (125-127)). This ability of machines to explore and develop models with a level of complexity beyond what is readily interpretable by humans opens up new avenues for scientific progress, less constrained by human cognitive limitations. However, as discussed above, for basic science, there is epistemic value in human understanding that may outweigh the predictive power of AI scientists.
Another consequence of automation concerns the ways in
which empirical research is conducted. For example, automated systems can hypothesize and experiment in design spaces far beyond the reach of human cognitive capabilities (9, 119). Fur- thermore, the ability to collect large amounts of data cheaply may obviate frequent iterations between hypothesis generation, experimental design, and data collection. Instead, with the availability of large data sets, the problem of scientific discovery can be transformed into a model discovery problem more amenable to machine learning (11, 94, 128).  However, it is important to recognize that the success of a one-time large-scale data collection hinges on a well-defined experimental design space and the stability of the system under study, as constant changes in the system can undermine the effectiveness of this approach. Accordingly, adaptive experimental design may be needed to identify suitable design spaces (58).

Ethical implications.

Biases. While human biases influence every aspect of scientific work, automated systems are not immune to bias. They can inherit biases from their creators, the construction process, the data they use, and their training format (129). Examples include discrimina- tory biases in facial recognition technology (130), unrepresentative sampling in psychological experiments (116), and discrimination in automated participant recruitment processes (131). Moreover, automated literature reviews don't escape the biases inherent to the existing literature. These biases can be democratized and exacerbated by the pace of these systems, especially when

they are uninterpretable or operate as "black boxes." However, a potential advantage is that biases in automated systems may be easier to correct than in humans, such as by using more diverse data, or by aligning automated systems with societal norms.

Value alignment and responsibility. The risk of harmful biases and outcomes of automated processes call for their value alignment with broader societal norms.	This is particularly crucial as automation could potentially ease the path for malevolent entities to conduct research detrimental to society, such as developing chemical or biological weapons. Such outcomes underscore the necessity of ethics dedicated to addressing these issues, ensuring that automated scientific advancements align with human values. Consequences of automation also bring about the issue of responsibility: If a scientific discovery that affects the wider society is based on an automated process, who is responsible? The accountability for effects arising from harmful scientific practice remains ambiguous-whether it lies with the system's creator, its user, or the implementer of societal changes based on the system's output. This issue parallels broader debates in AI, such as liability in self-driving car accidents or the creation of automated artwork. Additionally, the potential misuse of powerful systems (e.g., a system suggesting harmful drug treatments) necessitates robust safeguards. The same applies to potential violations of data privacy. When automated systems generate contentious theories or design ethically questionable experiments, human oversight and responsibility are imperative. Importantly, ethical guidelines are often formulated by the institutions developing the systems (132), highlighting the need for an external framework that can
hold institutions accountable.

Conclusion
While the automation of scientific practice is currently confined mostly to well-defined engineering and discovery problems, there is the potential for automation to pervade a large part of scientific practice. We suggest that this trend represents not merely a series of quantitative changes, such as increased efficiency or precision in science, but brings about a fundamental shift in the

conduct of science. The integration of AI into scientific practice has the potential to overcome human cognitive limitations, thereby expanding our capabilities for discovery. Yet, this advance is not without challenges-data availability, computational complexity, engineering demands, and subjectivity of scientific task goals mark the technical boundaries of current automatability. Further- more, normative goals of science-anchored on societal values- potentially make complete automation of scientific practice neither desirable nor feasible. Finally, this qualitative shift comes with practical and ethical challenges that call for interdisciplinary and collective efforts from researchers, policymakers, and the broader community to navigate the future of science.

Disclosures
The authors have no competing interests to report.

Acknowledgments
S. Musslick and S. Mahesh were supported by Schmidt Science Fellows, in partnership with the Rhodes Trust. S. Musslick was also supported by the Carney BRAINSTORM program at Brown University and the National Science Foundation (2318549).
S. Mahesh also acknowledges the support of the Acceleration Consortium fellowship. S.J. Sloman acknowledges support from the UKRI Turing AI World-Leading Researcher Fellowship, [EP/W002973/1]. S. Chandramouli was supported by the Finnish Center for Artificial Intelligence, and Academy of Finland (328813); he also acknowledges the support from the Jorma Ollila Mobility Grant by Nokia Foundation. L. Bartlett and F. Gobet were sup- ported by European Research Council Grant ERC-ADG-835002- GEMS. T. L. Griffiths was supported by a grant from the NOMIS Foundation. R. D. King was supported by the Wallenberg AI, Autonomous Systems and Software Program (WASP) funded by the Knut and Alice Wallenberg Foundation, by Chalmers Artificial Intelligence Research Centre (CHAIR), and by the UK EPSRC grants EP/R022925/2 and EP/W004801/1. The authors thank Solomon Oyakhire for valuable feedback.



1 RD King, et al., Functional genomic hypothesis generation and experimentation by a robot scientist. Nature 427, 247-252 (2004) Publisher: Nature Publishing Group UK London.
2 RD King, et al., The automation of science. Science 324, 85-89 (2009) Publisher: American Association for the Advancement of Science.
3 G Raayoni, et al., Generating conjectures on fundamental constants with the Ramanujan Machine. Nature 590, 67-73 (2021) Publisher: Nature Publishing Group UK London.
4 A Davies, et al., Advancing mathematics by guiding human intuition with AI. Nature 600, 70-74 (2021) Publisher: Nature Publishing Group UK London.
5 AF de Almeida, R Moreira, T Rodrigues, Synthetic organic chemistry driven by artificial intelligence. Nat. Rev. Chem. 3, 589-604 (2019) Publisher: Nature Publishing Group UK London.
6 J Jumper, et al., Highly accurate protein structure prediction with AlphaFold. Nature 596, 583-589 (2021) Publisher: Nature Publishing Group.
7 RK Lindsay, Applications of artificial intelligence for organic chemistry: the DENDRAL project. (No Title) (1980).
8 D Boiko, R MacKnight, B Kline, others, Autonomous chemical research with large language models. Nature 624, 570-578 (2023) Publisher: Nature Publishing Group.
9 A Merchant, et al., Scaling deep learning for materials discovery. Nature (2023).
10 NJ Szymanski, et al., An autonomous laboratory for the accelerated synthesis of novel materials. Nature (2023).
11 JC Peterson, DD Bourgin, M Agrawal, D Reichman, TL Griffiths, Using large-scale experiments and machine learning to discover theories of human decision-making. Science 372, 1209-1214 (2021) Publisher: American Association for the Advancement of Science.
12 U.S. Department of Energy, Scientific Machine Learning for Complex Systems (2023) Published: Funding Announcement.
13 A Velasquez, Foundation Models for Scientific Discovery (FoundSci). Def. Adv. Res. Proj. Agency (DARPA) Program Solicitation (2023).
14 H Kitano, Nobel Turing Challenge: creating the engine for scientific discovery. npj Syst. Biol. Appl. 7, 29 (2021) Publisher: Nature Publishing Group UK London.
15 H Zenil, et al., The future of fundamental science led by generative closed-loop artificial intelligence. arXiv preprint arXiv:2307.07522 (2023).
16 A Birhane, A Kasirzadeh, D Leslie, S Wachter, Science in the age of large language models. Nat. Rev. Phys. pp. 1-4 (2023) Publisher: Nature Publishing Group UK London.
17 H Wang, et al., Scientific discovery in the age of artificial intelligence. Nature 620, 47-60 (2023) Publisher: Nature Publishing Group UK London.
18 M Binz, et al., How should the advent of large language models affect the practice of science? arXiv preprint arXiv:2312.03759 (2023).
19 M Dubova, M Galesic, RL Goldstone, Cognitive science of augmented intelligence. Cogn. Sci. 46, e13229 (2022) Publisher: Wiley Online Library.
20 H Moravec, Mind children: The future of robot and human intelligence. Harv. UP (1988).
21 M Dubova, et al., Is ockham's razor losing its edge? new perspectives on the principle of model parsimony. MetaArXiv preprint doi:10.31222/osf.io/bs5xe (2024).
22 P Langley, Scientific discovery: Computational explorations of the creative processes. (MIT press), (1987).
23 S Dz?eroski, P Langley, L Todorovski, Computational discovery of scientific knowledge in Computational discovery of scientific knowledge: introduction, techniques, and applications in environmental and life sciences. (Springer), pp. 1-14 (2007).
24 SM Udrescu, et al., AI Feynman 2.0: Pareto-optimal symbolic regression exploiting graph modularity. Adv. Neural Inf. Process. Syst. 33, 4860-4871 (2020).
25 M Cranmer, Interpretable machine learning for science with PySR and SymbolicRegression. jl. arXiv preprint arXiv:2305.01582 (2023).
26 M Landajuela, et al., Discovering symbolic policies with deep reinforcement learning. (PMLR), pp. 5979-5989 (2021).

27 S Li, I Marinescu, S Musslick, GFN-SR: Symbolic Regression with Generative Flow Networks. (2023).
28 RK Lindsay, BG Buchanan, EA Feigenbaum, J Lederberg, DENDRAL: a case study of the first expert system for scientific hypothesis formation. Artif. intelligence 61, 209-261 (1993) Publisher: Elsevier.
29 JE Saal, S Kirklin, M Aykol, B Meredig, C Wolverton, Materials design and discovery with high-throughput density functional theory: the open quantum materials database (OQMD). Jom 65, 1501-1509 (2013) Publisher: Springer.
30 A Jain, et al., Commentary: The Materials Project: A materials genome approach to accelerating materials innovation. APL materials 1 (2013) Publisher: AIP Publishing.
31 AM Liekens, et al., BioGraph: unsupervised biomedical knowledge discovery via automated hypothesis generation. Genome biology 12, 1-12 (2011) Publisher: BioMed Central.
32 JB Voytek, B Voytek, Automated cognome construction and semi-automated hypothesis generation. J. neuroscience methods 208, 92-100 (2012) Publisher: Elsevier.
33 S Musslick, et al., SweetPea: A standard language for factorial experimental design. Behav. Res. Methods pp. 1-25 (2020) Publisher: Springer.
34 M van Casteren, MH Davis, Mix, a program for pseudorandomization. Behav. research methods 38, 584-589 (2006) Publisher: Springer.
35 DJ Navarro, MA Pitt, IJ Myung, Assessing the distinguishability of models and the informativeness of data. Cogn. psychology 49, 47-84 (2004) Publisher: Elsevier.
36 JI Myung, MA Pitt, Optimal experimental design for model discrimination. Psychol. review 116, 499 (2009) Publisher: American Psychological Association.
37 DR Cavagnaro, JI Myung, MA Pitt, JV Kujala, Adaptive design optimization: A mutual information-based approach to model discrimination in cognitive science. Neural computation 22, 887-905 (2010) Publisher: MIT Press.
38 S Musslick, et al., An evaluation of experimental sampling strategies for autonomous empirical research in cognitive science. Vol. 45, (2023) Issue: 45.
39 K Williams, et al., Cheaper faster drug development validated by the repositioning of drugs against neglected tropical diseases. J. Royal society Interface 12, 20141289 (2015) Publisher: The Royal Society.
40 A Coutant, et al., Closed-loop cycles of experiment design, execution, and learning accelerate systems biology model development in yeast. Proc. Natl. Acad. Sci. 116, 18142-18147 (2019) Publisher: National Acad Sciences.
41 AB Watson, QUEST+: A general multidimensional Bayesian adaptive psychometric method. J. Vis. 17, 10-10 (2017) Publisher: The Association for Research in Vision and Ophthalmology.
42 S Valentin, et al., Designing Optimal Behavioral Experiments Using Machine Learning. arXiv preprint arXiv:2305.07721 (2023).
43 B Shababo, B Paige, A Pakman, L Paninski, Bayesian inference and online experimental design for mapping neural microcircuits. Adv. Neural Inf. Process. Syst. 26 (2013).
44 S Dushenko, K Ambal, RD McMichael, Sequential Bayesian experiment design for optically detected magnetic resonance of nitrogen-vacancy centers. Phys. review applied 14, 054036 (2020) Publisher: APS.
45 X Huan, YM Marzouk, Simulation-based optimal Bayesian experimental design for nonlinear systems. J. Comput. Phys. 232, 288-317 (2013) Publisher: Elsevier.
46 GN Kanda, et al., Robotic search for optimal cell culture in regenerative medicine. Elife 11, e77007 (2022) Publisher: eLife Sciences Publications Limited.
47 S Stanton, et al., Accelerating bayesian optimization for biological sequence design with denoising autoencoders. (PMLR), pp. 20459-20478 (2022).
48 K Korovina, et al., Chembo: Bayesian optimization of small organic molecules with synthesizable recommendations. (PMLR), pp. 3393-3403 (2020).
49 RR Griffiths, JM Herna´ndez-Lobato, Constrained Bayesian optimization for automatic chemical design using variational autoencoders. Chem. science 11, 577-586 (2020) Publisher: Royal Society of Chemistry.
50 Y Zhang, DW Apley, W Chen, Bayesian optimization for materials design with mixed quantitative and qualitative variables. Sci. reports 10, 4924 (2020) Publisher: Nature Publishing Group UK London.
51 AG Kusne, et al., On-the-fly closed-loop materials discovery via bayesian active learning. Nat. communications 11, 5966 (2020).
52 Q Liang, et al., Benchmarking the performance of Bayesian optimization across multiple experimental materials science domains. npj Comput. Mater. 7, 188 (2021) Publisher: Nature Publishing Group UK London.
53 C Papadimitriou, Optimal sensor placement methodology for parametric identification of structural systems. J. sound vibration 278, 923-947 (2004) Publisher: Elsevier.
54 J Chang, J Kim, BT Zhang, MA Pitt, JI Myung, Data-driven experimental design and model development using Gaussian process with active learning. Cogn. Psychol. 125, 101360 (2021) Publisher: Elsevier.
55 P Gru¨ nwald, T van Ommen, Inconsistency of Bayesian Inference for Misspecified Linear Models, and a Proposal for Repairing It. Bayesian Analysis 12, 1069 - 1103 (2017).
56 T Rainforth, A Foster, DR Ivanova, FB Smith, Modern bayesian experimental design. arXiv preprint arXiv:2302.14545 (2023).
57 SJ Sloman, "Towards Robust Bayesian Adaptive Design Methods for the Study of Human Behavior," PhD thesis, Carnegie Mellon University (2022).
58 M Dubova, A Moskvichev, K Zollman, Against theory-motivated experimentation in science. MetaArXiv. June 24 (2022).
59 R Gelpi, N Saxena, G Lifchits, D Buchsbaum, CG Lucas, Sampling heuristics for active function learning in Proceedings of the 43rd Annual Meeting of the Cognitive Science Society. (cognitivesciencesociety.org), (2021).
60 M Dubova, SJ Sloman, B Andrew, MR Nassar, S Musslick, Explore your experimental designs and theories before you exploit them! Behav. Brain Sci. 47, e40 (2024) Publisher: Cambridge University Press.
61 G Shin, et al., Wearable activity trackers, accuracy, adoption, acceptance and health impact: A systematic literature review. J. biomedical informatics 93, 103153 (2019) Publisher: Elsevier.
62 Juvenile Diabetes Research Foundation Continuous Glucose Monitoring Study Group, Effectiveness of continuous glucose monitoring in a clinical care environment: evidence from the Juvenile Diabetes Research Foundation continuous glucose monitoring (JDRF-CGM) trial. Diabetes care 33, 17-22 (2010) Publisher: Am Diabetes Assoc.
63 MA Lazzara, GA Weidner, LM Keller, JE Thom, JJ Cassano, Antarctic automatic weather station program: 30 years of polar observation. Bull. Am. Meteorol. Soc. 93, 1519-1537 (2012) Publisher: American Meteorological Society.
64 SM Wood, SP Johnson, JN Wood, Automated study challenges the existence of a foundational statistical-learning ability in newborn chicks. Psychol. Sci. 30, 1592-1602 (2019) Publisher: Sage Publications Sage CA: Los Angeles, CA.
65 TM Gureckis, et al., psiTurk: An open-source framework for conducting replicable behavioral experiments online. Behav. research methods 48, 829-842 (2016) Publisher: Springer.
66 W Mason, S Suri, Conducting behavioral research on Amazon's Mechanical Turk. Behav. research methods 44, 1-23 (2012) Publisher: Springer.
67 S Palan, C Schitter, Prolific. ac-A subject pool for online experiments. J. Behav. Exp. Finance 17, 22-27 (2018) Publisher: Elsevier.
68 B Thompson, B Van Opheusden, T Sumers, T Griffiths, Complex cognitive algorithms preserved by selective social learning in experimental populations. Science 376, 95-98 (2022).
69 B Carpenter, et al., Stan: A probabilistic programming language. J. statistical software 76 (2017) Publisher: NIH Public Access.
70 A Gelman, et al., Bayesian workflow. arXiv preprint arXiv:2011.01808 (2020).
71 C Steinruecken, E Smith, D Janz, J Lloyd, Z Ghahramani, The automatic statistician. Autom. machine learning: Methods, systems, challenges pp. 161-173 (2019) Publisher: Springer International Publishing.
72 F Gobet, M Addis, PC Lane, PD Sozou, Introduction: Scientific discovery in the social sciences. Sci. discovery social sciences pp. 1-7 (2019) Publisher: Springer.
73 BC Falkenhainer, RS Michalski, Integrating quantitative and qualitative discovery: the ABACUS system. Mach. Learn. 1, 367-401 (1986) Publisher: Springer.
74 DB Lenat, The ubiquity of discovery. Artif. Intell. 9, 257-285 (1977) Publisher: Elsevier.
75 P Langley, Data-driven discovery of physical laws. Cogn. Sci. 5, 31-54 (1981) Publisher: Elsevier.
76 L Bartlett, A Pirrone, N Javed, P Lane, F Gobet, Genetic programming for developing simple cognitive models. Vol. 45, (2023) Issue: 45.
77 E Frias-Martinez, F Gobet, Automatic generation of cognitive theories using genetic programming. Minds Mach. 17, 287-309 (2007) Publisher: Springer.
78 R Guimera`, et al., A Bayesian machine scientist to aid in the solution of challenging scientific problems. Sci. advances 6, eaav6971 (2020) Publisher: American Association for the Advancement of Science.
79 C Cornelio, et al., Combining data and theory for derivable scientific discovery with AI-Descartes. Nat. Commun. 14, 1777 (2023) Publisher: Nature Publishing Group UK London.
80 M Landajuela, et al., A unified framework for deep symbolic regression. Adv. Neural Inf. Process. Syst. 35, 33985-33998 (2022).
81 S Musslick, Recovering Quantitative Models of Human Information Processing with Differentiable Architecture Search. Vol. 43, p. d (2021) Issue: 45.
82 A Murari, et al., Data driven theory for knowledge discovery in the exact sciences with applications to thermonuclear fusion. Sci. Reports 10, 19858 (2020) Publisher: Nature Publishing Group UK London.
83 E Bilsland, et al., Yeast-based automated high-throughput screens to identify anti-parasitic lead compounds. Open Biol. 3, 120158 (2013) Publisher: The Royal Society.
84 E Bilsland, et al., Plasmodium dihydrofolate reductase is a second enzyme target for the antimalarial action of triclosan. Sci. Reports 8, 1038 (2018) Publisher: Nature Publishing Group UK London.
85 MB Lee, B Blue, M Muir, M Kaeberlein, The million-molecule challenge: a moonshot project to rapidly advance longevity intervention discovery. GeroScience pp. 1-11 (2023) Publisher: Springer.
86 JN Pitt, et al., WormBot, an open-source robotics platform for survival and behavior analysis in C. elegans. GeroScience 41, 961-973 (2019) Publisher: Springer.
87 MJ Tamasi, et al., Machine learning on a robotic platform for the design of polymer-protein hybrids. Adv. Mater. 34, 2201809 (2022) Publisher: Wiley Online Library.
88 BP MacLeod, et al., Self-driving laboratory for accelerated discovery of thin-film materials. Sci. Adv. 6, eaaz8867 (2020) Publisher: American Association for the Advancement of Science.
89 EA Pogue, et al., Closed-loop superconducting materials discovery. npj Comput. Mater. 9, 181 (2023).
90 S Musslick, Y Strittmatter, JG Holland, AutoRA: Automated Research Assistant for Closed-Loop Computational Discovery (2023).
91 C Lu, et al., The ai scientist: Towards fully automated open-ended scientific discovery. arXiv preprint arXiv:2408.06292 (2024).
92 D Dillion, N Tandon, Y Gu, K Gray, Can ai language models replace human participants? Trends Cogn. Sci. 27, 597-600 (2023).
93 BK Petersen, et al., Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients in International Conference on Learning Representations. (2021).

94 A Almaatouq, et al., Beyond playing 20 questions with nature: Integrative experiment design in the social and behavioral sciences. Behav. Brain Sci. pp. 1-55 (2022) Publisher: Cambridge University Press.
95 MK Eckstein, C Summerfield, ND Daw, KJ Miller, Predictive and Interpretable: Combining Artificial Neural Networks and Classic Cognitive Models to Understand Human Learning and Decision Making.
bioRxiv pp. 2023-05 (2023) Publisher: Cold Spring Harbor Laboratory.
96 L Ji-An, MK Benna, MG Mattar, Automatic Discovery of Cognitive Strategies with Tiny Recurrent Neural Networks. bioRxiv pp. 2023-04 (2023) Publisher: Cold Spring Harbor Laboratory.
97 P Subash, et al., A comparison of neuroelectrophysiology databases. Sci. Data 10, 719 (2023).
98 KJ Gorgolewski, et al., The brain imaging data structure, a format for organizing and describing outputs of neuroimaging experiments. Sci. data 3, 1-9 (2016) Publisher: Nature Publishing Group.
99 J Hewson, Y Strittmatter, I Marinescu, C Williams, S Musslick, Bayesian Machine Scientist for Model Discovery in Psychology. (2023).
100 R Cory-Wright, C Cornelio, S Dash, B El Khadir, L Horesh, Evolving scientific discovery by unifying data and background knowledge with ai hilbert. Nat. Commun. 15, 5922 (2024).
101 AC Dama, et al., Bacterai maps microbial metabolism without prior knowledge. Nat. Microbiol. 8, 1018-1025 (2023).
102 SJ Sloman, DM Oppenheimer, SB Broomell, CR Shalizi, Characterizing the robustness of Bayesian adaptive experimental designs to active learning bias. arXiv preprint arXiv:2205.13698 (2022).
103 SJ Sloman, DR Cavagnaro, SB Broomell, Knowing what to know: Implications of the choice of prior distribution on the behavior of adaptive design optimization. Behav. Res. Methods pp. 1-24 (2024).
104 RS Sutton, AG Barto, Reinforcement learning: An introduction. (MIT press), (2018).
105 JN Kutz, Machine Learning Methods for Reduced Order Modeling in Model Order Reduction and Applications: Cetraro, Italy 2021. (Springer), pp. 201-228 (2023).
106 P Conti, G Gobat, S Fresca, A Manzoni, A Frangi, Reduced order modeling of parametrized systems through autoencoders and SINDy approach: continuation of periodic solutions. Comput. Methods Appl. Mech. Eng. 411, 116072 (2023) Publisher: Elsevier.
107 A Mendible, SL Brunton, AY Aravkin, W Lowrie, JN Kutz, Dimensionality reduction and reduced-order modeling for traveling wave physics. Theor. Comput. Fluid Dyn. 34, 385-400 (2020) Publisher: Springer.
108 B Chen, et al., Automated discovery of fundamental variables hidden in experimental data. Nat. Comput. Sci. 2, 433-442 (2022) Publisher: Nature Publishing Group US New York.
109 S Schneider, JH Lee, MW Mathis, Learnable latent embeddings for joint behavioural and neural analysis. Nature pp. 1-9 (2023) Publisher: Nature Publishing Group UK London.
110 Y Zheng, et al., Large language models for scientific synthesis, inference and explanation. arXiv preprint arXiv:2310.07984 (2023).
111 N Guler, S Kirshner, R Vidgen, Artificial Intelligence Research in Business and Management: A Literature Review Leveraging Machine Learning and Large Language Models. Available at SSRN 4540834 (2023).
112 S Whitfield, MA Hofmann, Elicit: AI literature review research assistant. Public Serv. Q. 19, 201-207 (2023) Publisher: Taylor & Francis.
113 X Luo, et al., Large language models surpass human experts in predicting neuroscience results (2024).
114 M Chen, et al., Evaluating large language models trained on code. arXiv preprint arXiv:2107.03374 (2021).
115 Y Su, et al., HotGPT: How to Make Software Documentation More Useful with a Large Language Model? pp. 87-93 (2023).
116 J Henrich, SJ Heine, A Norenzayan, The weirdest people in the world? Behav. brain sciences 33, 61-83 (2010) Publisher: Cambridge University Press.
117 P Gleeson, et al., Integrating model development across computational neuroscience, cognitive science, and machine learning. Neuron 111, 1526-1530 (2023) Publisher: Elsevier.
118 P Rich, R de Haan, T Wareham, I van Rooij, How hard is cognitive science? Vol. 43, (2021) Issue: 43.
119 B Burger, et al., A mobile robotic chemist. Nature 583, 237-241 (2020) Publisher: Nature Publishing Group UK London.
120 L Messeri, M Crockett, Artificial intelligence and illusions of understanding in scientific research. Nature 627, 49-58 (2024).
121 J Chang, S Gerrish, C Wang, J Boyd-Graber, D Blei, Reading tea leaves: How humans interpret topic models. Adv. neural information processing systems 22 (2009).
122 L Bainbridge, Ironies of automation in Analysis, design and evaluation of man-machine systems. (Elsevier), pp. 129-135 (1983).
123 National Institutes of Health, The Use of Generative Artificial Intelligence Technologies is Prohibited for the NIH Peer Review Process (2023) Published: Available from NIH Grants.
124 M Belkin, D Hsu, S Ma, S Mandal, Reconciling modern machine-learning practice and the classical bias-variance trade-off. Proc. Natl. Acad. Sci. 116, 15849-15854 (2019).
125 J Frankle, M Carbin, The lottery ticket hypothesis: Finding sparse, trainable neural networks. arXiv preprint arXiv:1803.03635 (2018).
126 Z Li, et al., Train big, then compress: Rethinking model size for efficient training and inference of transformers in International Conference on machine learning. (PMLR), pp. 5958-5968 (2020).
127 M Agrawal, JC Peterson, TL Griffiths, Scaling up psychology via scientific regret minimization. Proc. Natl. Acad. Sci. 117, 8825-8835 (2020) Publisher: National Acad Sciences.
128 TL Griffiths, Manifesto for a new (computational) cognitive revolution. Cognition 135, 21-23 (2015) Publisher: Elsevier.
129 L Daston, P Galison, Objectivity. (Princeton University Press), (2021).
130 J Buolamwini, T Gebru, Gender shades: Intersectional accuracy disparities in commercial gender classification. (PMLR), pp. 77-91 (2018).
131 L Yarger, F Cobb Payton, B Neupane, Algorithmic equity in the hiring of underrepresented IT job candidates. Online information review 44, 383-395 (2020) Publisher: Emerald Publishing Limited.
132 T Hagendorff, The ethics of AI ethics: An evaluation of guidelines. Minds machines 30, 99-120 (2020) Publisher: Springer.








